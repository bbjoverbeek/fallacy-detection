{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b086c70-7e43-4a05-90da-ba6de82b2ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:14:50.303868Z",
     "start_time": "2024-05-28T15:14:48.618514Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dfe578-4fb5-41b8-a088-75f6d575fb69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:14:52.211624Z",
     "start_time": "2024-05-28T15:14:52.126741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "def load_model(model_name=\"mosaicml/mpt-7b-instruct\"):\n",
    "    # Load the configuration with trust_remote_code set to True\n",
    "    config = transformers.AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(model_name, config=config, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "    model.to(device)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Setup the pipeline\n",
    "def setup_pipeline(model, tokenizer):\n",
    "    pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "    return pipe\n",
    "\n",
    "# Function to generate text based on prompts\n",
    "# Function to generate text based on prompts\n",
    "def generate_text(prompt, pipe, max_tokens=100):\n",
    "    response = pipe(\n",
    "        prompt, \n",
    "        max_length=max_tokens, \n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return response[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56abd847-2c2e-453c-95a5-8aa712e175b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:16:38.296389Z",
     "start_time": "2024-05-28T15:14:54.770279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb1fa8810904a05a4255ca710d2b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7812e37d240b6a1d8df1553d85b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_mpt.py:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b056da9174a478f992aef2f40fd0751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "attention.py:   0%|          | 0.00/24.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9d930fefa4471083449fb65e9e4252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norm.py:   0%|          | 0.00/3.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- norm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fbdf0c004848bc8bbc64291d47edc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fc.py:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- fc.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff403eb2fc624bec9f95b62b99658bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flash_attn_triton.py:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- attention.py\n",
      "- norm.py\n",
      "- fc.py\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a97b190b13748b590299e31a49127fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.py:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02038264964a4d10bd04ce708f8da937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ffn.py:   0%|          | 0.00/5.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- blocks.py\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666fb1339ce5411294435f3f56757520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "warnings.py:   0%|          | 0.00/894 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- warnings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- configuration_mpt.py\n",
      "- attention.py\n",
      "- blocks.py\n",
      "- warnings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/root/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:114: UserWarning: alibi or rope is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi or rope is turned on, setting `learned_pos_emb` to `False.`')\n",
      "/root/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7063019ff7462b96eb09eb7264d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20099dbfa1894dccad5fa9279d065e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aef4cfa9284ef7b9a5839ba7327d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa88858e93541fbbd39ce1cf50259c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_mpt.py:   0%|          | 0.00/32.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1703115601d43f4be79d3fce8cba9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_embedding.py:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- custom_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0509f759dd44dfda86ef168eb574e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta_init_context.py:   0%|          | 0.00/3.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- meta_init_context.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ca3bdb667b4bf990ae6ebb213e54be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "param_init_fns.py:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- param_init_fns.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb73aacad98408e92c1a8e10f2942e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_prefixlm_converter.py:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- hf_prefixlm_converter.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f4d4757984f09b6e648c6f816e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapt_tokenizer.py:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- modeling_mpt.py\n",
      "- custom_embedding.py\n",
      "- meta_init_context.py\n",
      "- param_init_fns.py\n",
      "- hf_prefixlm_converter.py\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ce0783917642a18623b7c09adf4a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30184eba85944d42a78a096a4767b2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5cea9f946948e98b0dd1cc03784f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be42b3c3f834ff986412963f6e537b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2e9524b79845d8a80ae13256c3a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287d155ce3ea4dcdb8c2d791bc466b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"mosaicml/mpt-7b-instruct\"  # You can change this to your specific model\n",
    "model, tokenizer = load_model(model_name)\n",
    "pipe = setup_pipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda0776d-8bd1-4874-8957-c9f2f6d705a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:25:03.536668Z",
     "start_time": "2024-05-28T15:24:57.548943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "The potential fallacious argument types are:\n",
      "AA slippery slope\n",
      "BB ad hominem\n",
      "CC appeal to (false) authority\n",
      "DD X appeal to majority\n",
      "EE No fallacy\n",
      "\n",
      "Which one of these 5 fallacious argument types does the following text contain?\n",
      "\"Groucho Marx said, \"Who do you believe? -- me, or your own eyes?''\"\n",
      "\n",
      "Please choose an answer form AA,BB,CC,DD or EE.\n",
      "Before identifying the fallacy, explain your reasoning thoroughly. Your explanation should clarify why the specific fallacy applies to the given statement. This step is crucial!\n",
      "If you do not explain your reasoning, you will not receive credit for this question.\n",
      "### Response:\n",
      "The given statement contains an appeal to false authority fallacy. The fallacy is committed because the statement is based on a quote from Groucho Marx, which is an appeal to authority. However, the statement is false because the quote is misattributed. The quote is actually from Groucho Marx's brother, Chico, and was said in response to a question about whether or not to believe the speaker or their own eyes.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "# Define the function to read the prompt from a file\n",
    "def read_prompt_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompt = file.read().strip()\n",
    "    return prompt\n",
    "\n",
    "# Define the path to the prompt file\n",
    "prompt_file_path = 'prompt.txt'\n",
    "\n",
    "# Read the prompt from the file\n",
    "instruction = read_prompt_from_file(prompt_file_path)\n",
    "\n",
    "# Format the prompt according to the specified format\n",
    "formatted_prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction)\n",
    "\n",
    "# Print the formatted prompt to verify\n",
    "# print(\"Formatted Prompt:\\n\", formatted_prompt)\n",
    "\n",
    "# Assuming 'generate_text' and 'pipe' are defined elsewhere in your code\n",
    "output = generate_text(formatted_prompt, pipe, max_tokens=2000)  # Increase max_tokens if needed\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\\n\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
