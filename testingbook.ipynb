{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b086c70-7e43-4a05-90da-ba6de82b2ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:14:50.303868Z",
     "start_time": "2024-05-28T15:14:48.618514Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dfe578-4fb5-41b8-a088-75f6d575fb69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:14:52.211624Z",
     "start_time": "2024-05-28T15:14:52.126741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "def load_model(model_name=\"mosaicml/mpt-7b-instruct\"):\n",
    "    # Load the configuration with trust_remote_code set to True\n",
    "    config = transformers.AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(model_name, config=config, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "    model.to(device)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Setup the pipeline\n",
    "def setup_pipeline(model, tokenizer):\n",
    "    pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "    return pipe\n",
    "\n",
    "# Function to generate text based on prompts\n",
    "# Function to generate text based on prompts\n",
    "def generate_text(prompt, pipe, max_tokens=100):\n",
    "    response = pipe(\n",
    "        prompt, \n",
    "        max_length=max_tokens, \n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return response[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56abd847-2c2e-453c-95a5-8aa712e175b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:16:38.296389Z",
     "start_time": "2024-05-28T15:14:54.770279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb1fa8810904a05a4255ca710d2b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7812e37d240b6a1d8df1553d85b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_mpt.py:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b056da9174a478f992aef2f40fd0751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "attention.py:   0%|          | 0.00/24.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9d930fefa4471083449fb65e9e4252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norm.py:   0%|          | 0.00/3.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- norm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fbdf0c004848bc8bbc64291d47edc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fc.py:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- fc.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff403eb2fc624bec9f95b62b99658bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flash_attn_triton.py:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- attention.py\n",
      "- norm.py\n",
      "- fc.py\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a97b190b13748b590299e31a49127fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.py:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02038264964a4d10bd04ce708f8da937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ffn.py:   0%|          | 0.00/5.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- blocks.py\n",
      "- ffn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666fb1339ce5411294435f3f56757520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "warnings.py:   0%|          | 0.00/894 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- warnings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- configuration_mpt.py\n",
      "- attention.py\n",
      "- blocks.py\n",
      "- warnings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/root/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:114: UserWarning: alibi or rope is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi or rope is turned on, setting `learned_pos_emb` to `False.`')\n",
      "/root/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/7bf8dfd6c819cdb82e2f9d0b251f79ddd33314fb/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7063019ff7462b96eb09eb7264d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20099dbfa1894dccad5fa9279d065e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25aef4cfa9284ef7b9a5839ba7327d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa88858e93541fbbd39ce1cf50259c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_mpt.py:   0%|          | 0.00/32.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1703115601d43f4be79d3fce8cba9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_embedding.py:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- custom_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0509f759dd44dfda86ef168eb574e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta_init_context.py:   0%|          | 0.00/3.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- meta_init_context.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ca3bdb667b4bf990ae6ebb213e54be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "param_init_fns.py:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- param_init_fns.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb73aacad98408e92c1a8e10f2942e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_prefixlm_converter.py:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- hf_prefixlm_converter.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f4d4757984f09b6e648c6f816e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapt_tokenizer.py:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/mosaicml/mpt-7b-instruct:\n",
      "- modeling_mpt.py\n",
      "- custom_embedding.py\n",
      "- meta_init_context.py\n",
      "- param_init_fns.py\n",
      "- hf_prefixlm_converter.py\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ce0783917642a18623b7c09adf4a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30184eba85944d42a78a096a4767b2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5cea9f946948e98b0dd1cc03784f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be42b3c3f834ff986412963f6e537b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2e9524b79845d8a80ae13256c3a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287d155ce3ea4dcdb8c2d791bc466b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"mosaicml/mpt-7b-instruct\"  # You can change this to your specific model\n",
    "model, tokenizer = load_model(model_name)\n",
    "pipe = setup_pipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda0776d-8bd1-4874-8957-c9f2f6d705a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T15:25:03.536668Z",
     "start_time": "2024-05-28T15:24:57.548943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "### Instruction:\n",
      "The potential fallacious argument types are:\n",
      "AA slippery slope\n",
      "BB ad hominem\n",
      "CC appeal to (false) authority\n",
      "DD X appeal to majority\n",
      "EE No fallacy\n",
      "\n",
      "Which one of these 5 fallacious argument types does the following text contain?\n",
      "\"Groucho Marx said, \"Who do you believe? -- me, or your own eyes?''\"\n",
      "\n",
      "Please choose an answer form AA,BB,CC,DD or EE.\n",
      "Before identifying the fallacy, explain your reasoning thoroughly. Your explanation should clarify why the specific fallacy applies to the given statement. This step is crucial!\n",
      "If you do not explain your reasoning, you will not receive credit for this question.\n",
      "### Response:\n",
      "The given statement contains an appeal to false authority fallacy. The fallacy is committed because the statement is based on a quote from Groucho Marx, which is an appeal to authority. However, the statement is false because the quote is misattributed. The quote is actually from Groucho Marx's brother, Chico, and was said in response to a question about whether or not to believe the speaker or their own eyes.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "# Define the function to read the prompt from a file\n",
    "def read_prompt_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompt = file.read().strip()\n",
    "    return prompt\n",
    "\n",
    "# Define the path to the prompt file\n",
    "prompt_file_path = 'prompt.txt'\n",
    "\n",
    "# Read the prompt from the file\n",
    "instruction = read_prompt_from_file(prompt_file_path)\n",
    "\n",
    "# Format the prompt according to the specified format\n",
    "formatted_prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=instruction)\n",
    "\n",
    "# Print the formatted prompt to verify\n",
    "# print(\"Formatted Prompt:\\n\", formatted_prompt)\n",
    "\n",
    "# Assuming 'generate_text' and 'pipe' are defined elsewhere in your code\n",
    "output = generate_text(formatted_prompt, pipe, max_tokens=2000)  # Increase max_tokens if needed\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "372b3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \"TITLE: Endless Ledge Skip Campaign for Alts POST: Reading everyone's comments has made me change my opinion on having an adventure mode like thing in PoE. I keep seeing if an adventure mode needs to exist then why not just start a char at 68. then a couple months after that we'll see post about how people want to start at 90 just so they can kill bosses. Then a few months later we'll see people asking for a\"creative\" mode so they can have access to all items in the game so they don't have to farm, and i dont think that sets a good example as a community for a game that we all love.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Two of my best friends are really introverted, shy people, and they both have cats. That leads to me believe that most cat lovers are really shy.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: There is a difference between a'smurf' and an'alt'. Please learn it and stop using them interchangeably. POST: Someone once told me they have an\"alt\" cause their main account was too high of rank to play with their friends. It's exactly the same as smurfing.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Discussion Thread (Part 3): 2020 Presidential Race Democratic Debates - Post Debate | Night 2 POST: Joe Biden will lose to Trump if he is the nominee. The Democratic party clearly has not learned the right lesson from Hillary Clinton's miserable failure. NOBODY WANTS ESTABLISHMENT POLITICIANS ANYMORE. NOBODY LIKES THE STATUS QUO. Like Jesus Christ you think they would learn. POST: The status quo in America is that its the best its ever been. We live in one of the best societies in the best times that humans have ever experienced.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"America is the best place to live, because it's better than any other country.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Let us move now to the future. It is not enough to stand on this record because we are dealing with the most ruthless, fanatical... leaders that the world has ever seen. That is why I say that in this period of the sixties, America must move forward in every area.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Delores is a big supporter for equal pay for equal work. This is the same policy that all those extreme feminist groups support. Extremists like Delores should not be taken seriously -- at least politically.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"\"Four out of five dentists recommend Happy Glossy toothpaste. Therefore, it must be great.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Gatineau police officer tests positive, but masks still not mandatory at checkpoints POST: Guess what? police need to interact with people at close quarters. they often need to touch or grapple. The masks do little. Cool it. Once they wear masks your anxiety will force you to demand the next step. biohazard suits? get real.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The last Democrat winner of the New Hampshire primary won the general election. This year, the winner of the New Hampshire primary will win the general election.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Men score better on math than women do. Jerry is a man. Therefore, Jerry is better at math than Sylvia, who is a woman.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Sign petition for Persona 5 pc and switch ports POST: So much important stuff in the world that needs political activism. Makes a petition to portbeg P5 onto PC and Switch.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Carbon dioxide hurts nobody' s health. It' s good for plants. Climate change need not endanger anyone.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Mr. Governor issues a proclamation for the people of his state to pray for rain. Several months later, it rains. Praise the gods!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Iran has moved forward with its nuclear weapons program. They're more dangerous today than they were four years ago. North Korea has moved forward with their nuclear weapons program, gone from one to two nuclear weapons to six to eight nuclear weapons. This vice president has been an advocate for over a decade for lifting sanctions against Iran, the largest state sponsor of terrorism on the planet. It's a mistake.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Sweden sees higher coronavirus death rate than US after refusing lockdown POST: I wonder how is New York planning on getting out of the lockdown, because when they get out of lockdown probably some cases are going to be going on and the whole infection thing will start again. POST: You cant stop nature. Youre going to be infected if you havent already. We are always trying to fight nature. We just have to let it run its course.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Jeff is preparing to create a commercial for a new energy drink. He visits a local high school and surveys students in an English class about their beverage preferences. The majority of the class says they prefer grape flavored drinks, so Jeff tells his superiors that grape is the flavor favored most by high school students. What error in reasoning has Jeff made?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The Freehold Raceway Mall is the best mall because there are always so many cars there.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Can I get into finance with a Law degree? POST: I have a JD, an MBA, and an MSF so I am pretty well versed in the skill sets. What about a JD would make you think you could do finance? It is a pretty in depth math program. There are some advanced math skills needed that are covered nowhere in undergrad or a JD unless you were also a finance major for BS. This is law school arrogance at its finest. Why not a brain surgeon?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The sea-ice loss is President Vladimir Putin' s gain. Already the largest country on the planet, Russia stands to gain access to shipping routes and energy reserves, and a strategic military advantage from the opening of the Arctic. Along the Russian coastline, which makes up more than half the Arctic total, winds and currents push old ice away from potential shipping lanes and prevent the build-up of thicker, multi-year ice that would leave other parts of the Arctic impassable for longer periods.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"My first day of basketball practice was easy, so it will always be easy.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Brandon: We should have tastier lunches! Jaylen: Don't listen to him! He's a terrible person! I saw him trip another student and steal his lunch money!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Sound familiar? POST: ok but can I just say - no his doesn't sound familiar. The left is asking for expanding background checks, closing the gun show loop hole, maybe registering firearms and creating a system that addresses or catches strawman purchases. We don't need to play this strawman argument game. And we don't need to do the\"slippery slope\" thing either. Reasonable regulations doesn't lead to the fed keeping lists and someday coming after all gun owners to suppress the working class.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"Several years ago, a group of 10 psychologists started a psychology training program. Each of those psychologists is efficient, effective, and highly-regarded. Their training program must be efficient, effective, and highly-regarded.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I lost my phone in the living room, so it will always be in the living room when it is lost.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Bar in Thurles in trouble over ad featuring Jesus with a pint. Christians are slowly becoming bigger snowflakes than Muslims. POST: So was the bar burned by a mob and the owner killed? If not, Christians have a ways to go before they are on par with Muslims.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Now We Know Who Sold the Bottom at $6k And Tried To Crash Bitcoin - Spoiler alert: it was Mt.Gox trustee POST: can anyone explain the part where it says he tried to crash the market at 6k?.... i dont get the reasoning behind this? POST: If you sell at high prices, that makes sense, doesn't it? If you sell at bottom, you're either panicking or trying to crash the price of the asset you're selling. So if he sold big amounts at 6k, he tried to bring the price even lower and cause a total sell off. That is my logic.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Transgender brain scans promised as study shows structural differences in people with gender dysphoria POST: So now the far left is going to have to admit that there is a difference between the brains of men and women and their behavior isn't just a social construct that is created by what toys they are raised with? Looks like the exception is charging to the rescue of the norm. Plot twist!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The spider that bit was poison, therefore all spiders are poison.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Next week he will be in Paris, a city terrorized yet again by mass murderers, for a summit with other world leaders on climate change, not terrorism. What precisely makes these world leaders so convinced that climate change is a more urgent and massive threat than the incessant rampages of Islamist violence? It can not be what is happening to world temperatures, because they have gone up only very slowly, less than half as fast as the scientific consensus predicted in 1990 when the global-warming scare began in earnest.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"These are unidentified people, and after the bomb goes off, they're blown to bits because they are suicidal individuals who think they're going to go to paradise if they perpetrate such an act and lose their life in doing it. We are going to, as I say, we're busy trying to find the centers where these operations stem from, and retaliation will be taken. But we're not going to simply kill some people to say,\"Oh, look, we got even.''\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"smoking cigarettes is deadly because cigarettes can kill you\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: To guilt people into not buying meat POST: Comment overwritten by Power Delete Suite for privacy purpose. POST: Do any of you self-righteous pricks understand in the slightest capacity how nature works? There are 4.6 BILLION FUCKING YEARS of evolution on this planet across hundreds upon hundreds of millions of species and not a goddamned one of them, with the exception of you idiots, has any problem with killing for food. It's in the DNA of every single creature on this planet, and it's the SOLE FUCKING REASON that either of us exist. Killing for food is 100% acceptable and morally right, and the suffering of the animals involved is fucking irrelevant. Lions don't give a fuck about the screams of a wildebeest as they disembowel it for a dinner. There is nothing, save for your ego, that gives you a reason to act or feel any different.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Everybody who's looked at it, 500 economists, seven Nobel prize winners, say it's bad for the economy. It's going to blow a hole in the deficit It's going to raise taxes on nine million people and require bigger cuts than the one I vetoed. Our plan is better, it will take us into the future with a growing economy and healthier families.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"If indoor smoking laws are passed for bars, the bars will go out of business since people who drink, smoke while they drink.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"You should drive on the right side of the road because that is what the law says, and the law is the law.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: But I read an article! POST: Honestly though, a PhD is not necessary to have an informed opinion. If that were the case, a lot of pro vaxxers wouldn't have an informed opinion either and let's be honest: they don't. Herd mentality is as much a thing as herd immunity. What antivaxxers need is someone with a PhD drawing a conclusion they agree with so they can repeat and circlejerk that to oblivion. And someone with a PhD should know the difference between an actual result and\"oh hey one number out of 100 says this so it must be true\". And even then they will be a minority, but at least it can sufficiently instigate some doubt.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I'm proud of that. It happened because I could work with people -- Republicans and Democrats. That's why we've had 24 retired generals and admirals, hundreds of business people, many of them Republican, support this campaign. You have to decide whether you want to change or not.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Fortnite is the best game ever. Everyone is playing it!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Every sunrise, the rooster makes a sound. So it is the rooster which makes the sun rise.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I passed my math test after going out to the movies the night before. I should go to the movies the night before every math test!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"According to Freud, your belief in God stems from your need for a strong father figure. So don't you see that it's silly to continue believing in God?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: AITA for getting pissed that my (now) vegan GF refuses to live with me if I eat meat? POST: Human are omnivores. End of argument. If she doesnt want to live with meat eating, make a parenting plan in court and she can pay child support for the kid that lives with you fill time that she wont raise since meat is around. Easy.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Don't forget to offer acts of reparation for the frequent acts of desecration/sacrilege against the Eucharist POST: I got into a discussion with someone on here who claimed that even though he supported legalized abortion and was pro choice he still received. It broke my heart. And he was flippant and dismissive. The Eucharist is not a reward or something you deserve if you are obstinate to church teachings POST: There are valid reasons to be both Catholic and support legalized abortion. Studies show that abortions occur just as frequently in nations where it is legal as nations where it is not. Nations with no legal abortions have higher rates of unsafe abortions, maternal death, and female teen suicide. We must care about the health and life of women too. These women are at their lowest and need compassion and safety. If restricting and banning abortion doesn't lower the rates of abortions, but instead causes more harm and death, it is not a good policy. <URL> Choosing compassion over virtue signaling should not place any individual in mortal sin. After all, 51% of US Catholics believe abortion should be legal in all or most cases. <URL>\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: So Pointy! POST: I dont have to justify it, vegans assume most people consider an animal life to be on par with human life, its not. If I was in the position to save my pet or a stranger Id never met before of course I would save the human. I dont want animals to suffer and I earn enough that I can afford to buy free range meat from reliable sources, I dont feel bad that an animal was killed so I can eat it, I dont believe its wrong in anyway so long as while its alive it isnt mistreated. There is nothing morally wrong about killing animals for food, you realise animals kill other animals for food too right?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"If you would have supported that attitude -- if you would have supported that attitude, we would not have won the Cold War. We won the Cold War because we invested and we went forward. (APPLAUSE.)\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"He was born to Catholic parents and raised as a Catholic until his confirmation in 8th grade. Therefore, he is bound to want to defend some Catholic traditions and, therefore, cannot be taken seriously.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Every action being taken against terrorists requires court order, requires scrutiny. As a matter of fact, the tools now given to the terrorist fighters are the same tools that we've been using against drug dealers and white-collar criminals. So I really don't think so.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"My way of responding to difficult patients is by far the most ethical because no other way is so ethical and it is the only way that is completely ethical.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Thirty years after Tiananmen, protesters' goals further away than ever:\"Now, democracy is not only facing problems in China. Democracy cannot survive if China is the global power.\" POST: Well, democracy gave us Trump to the whole world. I'll let others judge what democracy is. POST: Lets see what other system gave us. Communism gave us the Kim dynasty that destroyed their own country. Fascism gave us Franco that kept his country decades in the past in every manner. Monarchism gave us Leopold II of Belgium who committed genocides in Africa Theocracy gave us Pope John XII who fucked half of rome So as we can easily gather, every for of government had its share of shitty figureheads. That doesnt prove anything. At least in democracy we have the chance to switch them, you know what they do in other forms of government? Wait. North korea is still waiting on the Kim dynasty to die off, Spain had to wait until Franco dies to start modernizing, the people of Congo had to wait until Leo II died so they can stop getting killed, and the catholic world had to wait until John XII to normalize again.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Chihuahuas are good inside dogs. German Shepherds are dogs; therefore, German Shepherds would be good inside dogs, too.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Explain why you find sausages, lasagna, steak, and tacos delicious like I am your crazy extremist vegan girlfriend who believes eating cheese, let alone meat, is worse than the holocaust. POST: Most animals, including humans are meant to consume meat. Humans would've probably died out by eating vegetables alone. So why not doing what we were meant to do by enjoying some salmon? Or do you actually think fish is okay since you don't think they look cute?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The United States is the wealthiest nation in the world. So every American is wealthy.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Sam is riding her bike in her home town in Maine, minding her own business. A station wagon comes up behind her and the driver starts beeping his horn and then tries to force her off the road. As he goes by, the driver yells\"get on the sidewalk where you belong!\" Sam sees that the car has Ohio plates and concludes that all Ohio drivers are jerks.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Florida officer planted drugs on over 100 victims: DA has not moved to vacate any charges against his victims, some of whom are still imprisoned[2019] POST: Wow, over 100 victims... that's horrible. What was the motive behind such a terrible way of life, and personality? POST: Advancement and maybe kickbacks? Either that or he's just a psychopath who gets off on destroying people's lives. Either way this asshole should never see the light of day again.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"only man is rational no women is man Therefore, no women is rational\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"You should never gamble. Once you start gambling you find it hard to stop. Soon you are spending all your money on gambling, and eventually you will turn to crime to support your earnings.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"If it is very low, for instance around one, it means greenhouse gas emissions are simply not worth doing anything about. But if ECS is high -- say, around four degrees or more -- then climate change is probably a big problem. We may not be able to stop it, but we' d better get ready to adapt to it.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Vote Leave fined and reported to police by Electoral Commission - The Guardian POST: Two groups working towards the same goal shared some information. Big deal. Hopefully the police will use their resources on more serious issues such as knife crime, drug gangs and scooter criminals.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Bigfoot reportedly seen, going INSIDE a UFO. This has got to be the strangest thing I have came across. Were the Missing, brought inside the UFO, too? POST: Interesting story, but sadly no substantial evidence. Mostly likely a lie for attention. POST: From a practicing judge?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: The only conspiracy theory I accept POST: Post is same age as me and hes make bills while I'm slaving away at school and work POST: Yeah, but if youre on Reddit you're probably not one of the millions upon millions of people who are starving or hungry or living in one of the shit holes of the world. Or at least that's my guess. So don't be upset someone is your age and way luckier than you, be thankful you weren't born into worse circumstances because there are likely plenty. Also, fun fact, they've done studies and if you make around $80k in the US anything beyond that doesn't really contribute to your overall happiness. I think what's cooler about Post Malone and other wildly successful people is they are doing what they love doing. That's real success. And you don't need to be a millionaire to have it.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"We know God exists because he made everything\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Incel gets into relationship POST: Its almost like virginity has no bearing on who you are as a person and once you lose it you're still the same as you were before... POST: 2 chicks rejected me for being a virgin. I had sex as soon as I started lying about having had sex. And all those weren't even casual sex, it was in the frame of relationships. Apparently it holds bearing on who you are as a person and you're not the same person when you loose it.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I know that our TV advertisements are more effective than radio. The numbers show that we hit twice the audience with TV, and our focus groups remember the TV commercial 38 percent more than the radio slot.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What would people think about preventing people from switching out from a pilot seat? i.e. to a gunner position; you'd still be able to bail. POST: This is a ridiculous post and this mechanic will never be changed. Seat switching has always been a BF mechanic. Dont sit here and try and talk about realism or how you shouldnt be able to swap instantly between seats when there is hardly anything realistic about BF vehicle play in general. Sounds like you need to get better if you are having trouble shooting down the most vulnerable aircraft in the sky.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Pete Davidson accounted for after disturbing post;'SNL' cast member deletes Instagram. POST: Social media is the worst. People don't realize how much of an effect it has on someone, especially his generation. Anyone in the public eye who has any sort of mental health issue should rid themselves of their accounts if they possibly can. I understand studios force some actors to be active there, but if it's the difference between leading a happy, healthy life or getting a movie role, it really should be an easy decision. POST: Really, the worst? China has people in internment camps and people in the middle east get stoned for not wearing head scarves, but it's social media that's the worst? I think that's a massive exaggeration. Edit: I feel like I need to clarify that I'm not trying to deny what Pete is going through. I am however annoyed by a reference to a social media being\"the worst\". I'd even argue that saying that undermines the worse problems that he likely has going on here.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Mr. Gough supports the cell phone ban and he's an idiot, so we should let teachers keep their cell phones.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Bill, you drive a beat-up car from the 1980s. For this reason, we can never allow you to be a lifeguard at the community pool.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The teenagers where rude and disrespectful therefore all teenagers are rude and disrespectful.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE:'A historic day': Switzerland votes to back new anti-homophobia law POST: This is cool and all, but I'm glad it's not being passed in a country where I live. If you give the government *any* control over what is considered\"hate speech\", you are basically relinquishing your freedom of speech. It's a slippery slope. For example: saying\"hateful\" things about Islam becomes illegal. Let's say you criticise Sharia laws (laws based off of the rules set out in Islam for those who are unaware). Next thing you know, your own government has full power to censor this\"hate\", and you are persecuted simply for disagreeing with the laws of an ally nation. Governments have shown time and time again that they are more than happy to censor and abuse their peoples. Don't ever relinquish your freedoms willingly.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"This movie was #1 at the box office last weekend! That means it must be really good!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"\"If we ban Hummers because they are bad for the environment, then eventually the government will ban all cars; therefore, we should not ban Hummers.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"My roommate from Maine loves lobsters, therefore all people from Maine love lobsters.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Cannabis is effective at reducing pain, and may be an alternative to opioids, with relatively minimal negative side effects, suggests new study of mobile app data, which found that the average user had a 3-point drop in pain suffering on a 0-10 point scale immediately following cannabis consumption. POST: I worked in an engineering factory for years and was never supplied a back belt so I now have a bad back and the only way I can get any sleep is to take 4 pain killers before bed or smoke one joint so I'll stick to what's natural rather than use so many painkillers my liver will be useless in a few years so cannabis for the win with me\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Islamophobia has become normal. Our challenge now is dismantling it without doing more damage POST: There must be a firm basis to people hating Islam. There are many of us and we can't all be wrong. Am i afraid of Islam and what it can do to this country? You are damn right i am and with good reason. With my own two eyes i have seen how it destroys countries, Islamic countries none the less. People that support this religion blowing each other up. You are doing a dis-service to your country being\"politically correct\" in regard to Islam and your children will suffer because of it.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: California court backs state's right to ban foie gras POST: Good thing CA is able to focus on this hugely important issue and doesn't have massive homelessness plaguing it's cities or an ever increasing affordable housing crisis to worry about. This and banning plastic straws are the issues we need to solve to create a better life and society for people. I'm so glad CA is at the forefront of tackling our nation's most pressing issues. Keep being a beacon of hope CA and I'm sure other states will follow.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"OBAMA: Well, I want to thank Senator McCain and Bob for moderating. I think we all know America is going through tough times right now. The policies of the last eight years and -- and Washington's unwillingness to tackle the tough problems for decades has left us in the worst economic crisis since the Great Depression. And that's why the biggest risk we could take right now is to adopt the same failed policies and the same failed politics that we've seen over the last eight years and somehow expect a different result.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Abstinence vs. those who chose to have sex, a dilemma I'd like to understand! POST: I dont wait until marriage, because I'm not even sure if I want to get married. Used to care about how many people the girl sleeped with, now I really dont give a shit. Ive collectively had sex hundreds of times with my partners over the years, that doesn't make me better than someone who's had sex with more people, one time each. POST: Almost everyone in the world will look more favorably on a person who has had sex 100x times with one person versus having sex 1x each with 100 different people. As they should.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: 1930s IWW cartoon on the 4 hour work day POST: I work 6 ten hour days very frequently and don't get weekends off. In a way it's pretty insulting to see people angry with a 9-5 40 hour work week. I'd be so grateful to have that extra time to spend with my family and friends.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"A few students are misbehaving...therefore the whole class is bad.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: It seems that eliminating sugar is the single thing everyone can agree on POST: Not at all. Years ago was fats. Everyone blamed fats. Now is the same with sugar. It is not just one thing. You must have a balance diet and a helthy lifestyle to achieve the final goal of health (and enjoy the process) POST: Not to jump down your throat here but'balanced' is such a loaded term. It implies an existing framework of what the extremes of diet are or can be. For example, if we're speaking'natural' diet. Balance can't include any refined sugar at all because we weren't able to process it. Before the food pyramid came around the upper end of sugar consumption would have been much lower. So that middle ground'balance' would be much less as well.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"But irrespective of whether he thinks it is or not means less than fact that this country cannot morally and socially and economically accept an economy running out the clock on the 20th Century. We're treading water. We have families that are hurting. We have people who are unemployed. We have people with no property. We have an administration that is demolishing public housing in our inner cities and not providing anything else but more public housing. Their solution to the inner city is more -- excuse the expression but it's true,\"socialism.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Michael Jackson, Kurt Cobain, and Jimi Hendrix were rock stars who died young. Therefore, if you become a rock star, don't expect to live a long life.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Over 5 million Filipinos use our products. It's time to switch to our brand now!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"MARVIN STONE: You suggest that we scrap the SALT II treaty already negotiated, and intensify the build-up of American power to induce the Soviets to sign a new treaty - one more favorable to us. President Carter, on the other hand, says he will again try to convince a reluctant Congress to ratify the present treaty on the grounds it's the best we can hope to get. Now, both of you cannot be right. Will you tell us why you think you are? RONALD REAGAN: Yes. I think I'm right because I believe that we must have a consistent foreign policy, a strong America, and a strong economy. And then, as we build up our national security, to restore our margin of safety, we at the same time try to restrain the Soviet build-up, which has been going forward at a rapid pace, and for quite some time. October 28, 1980 Cleveland, Ohio What logical fallacy did Reagan's response illustrate the use of?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: The bible is not Clear POST: The bible is not Clear it's clear enough so that there are 2.18 billion Christians A comprehensive demographic study of more than 200 countries finds that there are 2.18 billion Christians of all ages around the world, representing nearly a third of the estimated 2010 global population of 6.9 billion. <URL>\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I have been in charge of this reinventing government streamlining project that's reduced the size of government by more than 300,000 people in the last several years. And the budget plan that I've put out, according to the\"Los Angeles Times\" again, the way these things are typically measured as a percentage of the GDP, will bring government spending down to the lowest level in 50 years. So I want to proceed carefully to cover more people.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: What distinguishes\"food animals\" from\"not food animals\"? POST: Animals aren't food for us. If you wouldn't eat a dog or cat, don't eat a cow or chicken. Even if you would eat a dog or cat, don't. POST: Animals are food for other animals, why they wouldn't be food for humans?\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"The president of Honduras is a good leader because he is a leader of the country.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"And he cut defense an extra $60 billion, threw a lot of people out of work. He talks about a smaller government. There are actually more people in government except for people in defense related jobs. They're gone. The government's bigger than it was when President Kennedy was around, even though he says it's not. In addition, Republican Congress cut $53 billion.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"Families communicate less and less in the past forty years since feminism became mainstream. Feminism is to blame for this deterioration in the family.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"CLINTON: Our military is the strongest military in the world. It is the strongest, best prepared, best equipped it has ever been. There is very little difference in the budget that I proposed and the Republican budget over the next six-year period.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Murder is morally wrong. Therefore, abortion is morally wrong.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Violent video games cause teens to be violent, because violent teens play violent video games.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"These test results are clearly wrong, and it must be either because the client was malingering or because I bungled the test administration. Taking another look at the test manual, I see now that I bungled the test administration. Therefore the client was not malingering.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Trump's plan to improve healthcare, that everyone said wouldn't work, is already working POST: Is that why my prescriptions and premiums keep going up massively? hm. Trump hasn't done shit to improve healthcare, he has done the complete opposite.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: This though... POST: So freaking true...I recently got a $100k+ job without a college degree, before my 30th birthday. I did it because I worked my ass off and learned a skill in the military. It's not that hard you just got to do the best you can.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Workers that don't immediately respond to customers should be fired. POST: >I've never been satisfied with any businesses anywhere. If if smells like shit where ever you go, check your shoe. Or put another way If you run into an asshole in the morning, you ran into an asshole. If you run into assholes all day, you're the asshole.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"For want of a nail the shoe was lost. For want of a shoe the horse was lost. For want of a horse the rider was lost. For want of a rider the battle was lost. For want of a battle the kingdom was lost. And all for the want of a nail.\"For Want of a Nail,\" medieval proverb\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"\"I bought a ticket to win a new car at the mall, since I have never won anything like that in the past.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Old quote, but a good one POST: What are the reasons for viewing regulated hunting in the same light as factory farming? I went veg because factory farming is horribly unnatural, but I can't really come up with an argument against hunting based on what made me go veg... POST: I'm vegan, I'll never part take in this activity, but I don't feel like hunting for fun should be considered a mental illness. Our ancestors used to depend on it to survive, so I can see how it might be in someone's genome to want to hunt. Hunting is almost entirely aligned with the natural cycle of life, factory farming in horrible conditions isn't. Downvotes incoming\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: CMV: You can't justify eating meat POST: Cooking and eating meat is an artistic practice with thousands of years of history. My choice to cook and eat meat is a choice to participate in the continuation of this art form. I support eating meat for the same reason I would support classical music, theater, or sculpture: because I support art. And I am generally skeptical of attempts at soft censorship of this art by shaming meat eaters.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"President Bush didn't. President Obama was right, he said that that was outrageous to have deficits as high as half a trillion dollars under the Bush years. He was right, but then he put in place deficits twice that size for every one of his four years.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: So I have more guns than I'd like to admit, but I feel like a lot of people shouldn't own guns. POST: The drunk guy I agree with, however the other two are perfectly fine. Most states have laws against carry while drinking. Someone choosing to open carry an AR isnt subject to your approval. They dont need you to think their are cool to exercise a right. 14 year olds are plenty old enough to be around loaded guns. They arent 4. I had guns in a safe in my bedroom from 10 years old. I had the key and ammo. Again, someone else's rights arent based on your approval. POST: Yeah its not just about my approval, pretty sure the majority of people in the U.S are against open carrying an AR. No one sees someone carrying a long gun in public and thinks wow look at them go, so glad they are exercising their rights. Theyre thinking Im glad I have my ccw so I can drop this motherfucker if he sneezes. And youre right, I should just assume that all 14 year olds were taught properly on how to handle firearms even if their parents are pieces of shit. I shouldnt care if he hurts himself or someone else because if I did Id just be infringing in someones rights. Glad your parents believed you wouldnt kill someone with a gun that young. Too bad other parents believed the same thing.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: PewDiePie is a racist piece of shit POST: > pewdiepie is extremely racist and very anti Semitic A) The use of\"extremely\" and\"very\" is hyperbolical bullshit. You know it and I know it. Please stop. B) There is nothing wrong with being racist or anti Semitic. Being tribal is a normal part of being human.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: It's not even close to legal POST: I disagree with every comment on this thread. Almost 3k upvotes show that most people agree with me. A furry is not something Ive ever seen in real life and I would not even know the term existed if not for these strange Reddit posts/comments. Its weird, its not socially or mentally healthy, its not a thing. Bring on the downvotes.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Even the Republican platform has criticized the lack of leadership in Mr. Ford and they've criticized the foreign policy of this administration. This is one instance where I agree with - with the Republican platform. I might say this in closing, and that is that as far as foreign policy goes, Mr. Kissinger has been the president of this country.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Weekly General Discussion - March 10, 2019 POST: alex jones is cuckoo bananas and joe organ just lets him ride on like a monkey on a pig with a cowboy hat. he thinks he's just hanging out with a buddy but what he fails to realize is that he has a huge platform with a fan base of highly impressionable young men who feel wronged by society and entitled to scream like a monkey on the back of a pig with a cowboy hat POST: Free speech bad\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Mrs. Miller taught your older brother, who was the class clown. She decides to be strict with you from the very first day of class because she thinks you will be a clown, too.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Is it ideal to live without recreational drugs? POST: Ideal, perhaps for some. However it is highly unrealistic. Mankind has been using\"recreational drugs\" since we developed agriculture, and probably before too.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"James' mom is concerned when she finds out that he skipped class one day. She tells him that she is concerned that since he skipped one class, he will start skipping more frequently. Then he will drop out altogether, never graduate or get into college, and end up unemployed and living at home for the rest of his life.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: The more corrupt the state, the more numerous the laws. - Tacitus[529x529] POST: So the least corrupt state is anarchy by this logic. This is\"deep\" libertarian bullshit. Yes, over regulation is a thing, but laws against theft, murder, slavery, child labor, education, etc. are good things - not corruption. POST: > laws against theft, murder, slavery. Good people don't need laws to tell them how to be good, bad people either ignore laws or use/create them to hide behind...\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Stores should have a few for people who shop after closing POST: I mean 10 minutes after closing isn't really bad at all. POST: Well if 10 minutes isnt bad, then surely 11 is ok. If 11 is ok then 13 is fine. If 13 is fine then whats wrong with 15. You said 15 is ok, 16 is just a minute more. Were at 16, Im finishing up and will be checked out by 18. See how it keeps getting stretched out????? When the goddamned sign says the store closes at 9:00 the fucking customers need to get the fuck out by 8:59. They had all day to get their shit taken care of. At 9 0 0 youre on my time.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Three congressional representatives have had affairs. Members of Congress are adulterers.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Tennessee Senator calls higher education a'liberal breeding ground,' calls to remove it all together POST: So he's saying liberals are better educated than conservatives. We agree. Trump isn't the only one who loves the poorly educated. POST: Or, more accurately, many liberal professors abuse their positions by attempting to force their political opinions into subjects they don't belong in, like the English professor who insists their students each write a paper on\"Why the GOP are terrorists\" and grade students poorly who disagree with that opinion (experienced that first hand). Many of the big name institutions have become incestuous single minded orgies which no longer challenge students to think out of the box, challenge assumed truths and seek to learn all they can, but instead have become factories to produce a very specific set of opinions and mindsets never to be questioned. This isn't a call to abolish higher learning, but I think the entire system needs to be reassessed, not only due to outrageous costs and access issues.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: What\"healthy\" food is actually way more unhealthy than most people think? POST: Incoming comments of things that are nutritious but people don't consider healthy because they're high in calories AND other random shit they read on a blog who's ultimate goal is to convince them to spend money on something at some point. Olive oil is healthy even though it has calories and fruit is healthy even though it has carbs. Dairy and red meat are fine - people have been consuming them for centuries and they did shit like building pyramids using just their hands. You don't need to live off of bland chicken breasts, broccoli, and scrambled eggs to be healthy. Also people need to learn the difference between added sugar and natural sugar. The sugar in fruit is not the same sugar in candy bars. I think one of the biggest reasons for the obesity epidemic in America is the over-complication of nutrition. A new food is\"unhealthy\" every week.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: There are now traffic cameras that can spot you using your phone while driving POST: Distracted driving is a HUGE problem but the fact that people are begging for a state run mass surveillance system is terrifying. It may seem innocuous and even helpful at first but the implications are tremendous. These are the first steps towards mass facial recognition and social credit systems... and people are clamoring for it. Its crazy.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"\"The Cardinals are the best football team because they're better than all the other teams. They're better than all the other teams because they're the best.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Thirty years of fast food: Greater variety, but more salt, larger portions, and added calories are potentially fueling the obesity epidemic, according to a new study. Despite the addition of some healthy menu items, fast food is even more unhealthy for you than it was 30 years ago. POST: But did they check slow food? Dollars to donuts that eating at an average restaurant is unhealthier than 30 years ago by an even wider margin. Fast food isn't fueling the obesity epidemic; FOOD is fueling the obesity epidemic. POST: Let's not forget Genetically Modified foods. They are not on our food chain.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Should I [23F] urge my husband [26M] to stop watching porn? POST: Yes. Porn has gained the support of popular culture, but it is unhealthy. It has been shown to make men more sexually aggressive, dissatisfied with their own sex lives, and contributes to the global sex trade. Viewing porn also causes prolonged dopamine exposure, which the brain will build resistance against - making it more difficult to feel joy from other daily activities. Porn is also highly addictive, and has diminishing returns over time, so a user will have to watch more porn, or more extreme porn, to get the same amount of dopamine. Check [fightthenewdrug.org](<URL>) for studies on the harmful effects of pornography. POST: Yeah, I always go to religious organizations to supply me with clear and objective scientific studies...\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"I merely say that the United States should meet its commitments to Que- to uh - Formosa and the Pescadores. But as Admiral Yarnell has said, and he's been supported by most military authority, these islands that we're now talking about are not worth the bones of a single American soldier; and I know how difficult it is to sustain troops close to the shore under artillery bombardment. And therefore, I think, we should make it very clear the disagreement between Mr. Nixon and myself.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: There is no good reason to take stories/accounts of miracles seriously POST: > There is no good reason to take stories/accounts of miracles seriously I propose that for a modern account of a miracle, if the person telling you the account is trustworthy, that is a reason to take the account seriously.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"He has smoked cigarettes his entire life and he doesn't have lung cancer. Therefore smoking doesn't cause lung cancer.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Clearly, uh it was maybe the right thing to do, but we did not go in with enough information. We caused problems in the first place by denying Caribbean countries and third-world countries a chance to trade freely in the United States. It causes economic problems and turmoil, and then we turn around, as we did in Mexico, having to bail them out. We caused the problem in the first place, and it cost us 20 to 50 billion to bail them out.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: London doctor objects to city's $880 fine calling it'punitive' POST: Punitive: inflicting punishment, punishing Seems about right. Fines are punishments. Calling a fine\"punitive\" is like calling a textbook\"educational\". The gov't has been going all out to educate people. Anyone who still doesn't know the rules by now just isn't bothering to educate themselves. POST: Yeah, this doctor is a moron. Not smart like you.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Lola: I don't think John would be a good fit to manage this project, because he doesn't have a lot of experience with project management. John: But you don't have a lot of experience in project management either!\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Trans people in UK could face rape charges if they don't reveal gender history. POST: Rightly so. I don't care how it makes trans people feel, the vast majority of people would want to know if someone was born a different sex to that which they're passing themselves off as.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Hanging pork with garlic sauce... or as my sister called it,\"laundry over dirt field\" POST: Well it's common in Sichuan where this dish is originated from to serve it like this, so it's not a stupid restaurant plating thing it's how it should be\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"And judgment is what we look for in the president of the United States of America. I'm proud that important military figures who are supporting me in this race: former Chairman of the Joint Chiefs of Staff John Shalikashvili; just yesterday, General Eisenhower's son, General John Eisenhower, endorsed me; General Admiral William Crown; General Tony McBeak, who ran the Air Force war so effectively for his father -- all believe I would make a stronger commander in chief. And they believe it because they know I would not take my eye off of the goal: Osama bin Laden.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Fred, the German, stole my wallet. Therefore, all Germans are thieves.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"Slavery is accepted by just about everyone in our society, so it's ethical to keep slaves.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Need identify 2 lost parts. Dell inspiron 15 5577\n",
      "\n",
      "POST: Hi, those are SMD components. You need a parts list or a donor board. EDIT: The good news is they will be cheap, the bad news is you need someone who can do smd soldering, which, for no good reason, is a dark art. Check out Lewis Rossman on youtube to see tutorials, but it will require expensive kit, unless you can borrow some.\n",
      "\n",
      "POST: I live in not rich country here more good repair specialist. I see on motherboard 4 types of smd components already with identification. But they very similar. Thanks\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Innisfree?\n",
      "\n",
      "POST: I just picked up one of the tinted balms and it's a really lovely product. Nice tint, smooth, stays on.\n",
      "\n",
      "POST: Is the color really obvious? I prefer non tint\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: EXTRA! EXTRA!\n",
      "\n",
      "POST: When Reddit can't get more unoriginal\n",
      "\n",
      "POST: Have you not know that this poster is extremely popular in Oculus sub reddit? He creates those \"news\" papers every time there is some big news and people love it. Just look at the points in linked thread\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: G751JM. What the hell now? Please help. Is the laptop dead? Thank you, have a nice day\n",
      "\n",
      "POST: Enter Bios and see if your hdd is detected. If it is, might be an issue with boot order. Else try this: <URL>\n",
      "\n",
      "POST: Thanks, but what should I enter? Could you tell me step by step because I have no idea what you just said. Thanks for the help though\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: New Firefox Update\n",
      "\n",
      "POST: Dog software on cat hardware\n",
      "\n",
      "POST: Wouldn't it be the other way around? Since it looks like a dog and behaves like a cat.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Proof that Bots are manipulating the Rotten Tomatoes Audience score of The Last Jedi\n",
      "\n",
      "POST: Doesn't prove anything. Could just be an error. Most people I spoke to didn't like TLJ, so if anything, it should have a lower than 55% score.\n",
      "\n",
      "POST: Every IRL person I know loves it, all the hate coming from the internet. Anecdotal evidence works both ways\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Legion is the best overall expac we will ever get and here is why\n",
      "\n",
      "POST: This feels like definite nostalgia talking to me. Off the top of my head legiondaries were pretty bad bc it took so long to be able to target them. I remember getting the one I wanted for a character about a week before BFA dropped and not really being able to use it. Also was never really a fan of the AP grind tho I did love having my weapon always guaranteed. Order halls were also super hit or miss for me and I hated the rogue one. Spent most of my time in the Maelstrom and I liked it tho.\n",
      "\n",
      "POST: i think people focus too much on legendary acquisition and forgot how good the other parts of the xpac were. there werent many complaints at all except for legendary acquisition\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: People who are into dark humor, where do you draw the line?\n",
      "\n",
      "POST: I don't make fun of anyone's parents dying. I don't know, it's just a thing with me because I've been helping orphans for a long time and their mental health is seriously fucked up because of it.\n",
      "\n",
      "POST: It's very poor taste at the funeral.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Doctors have dismissed my symptoms, but I promise I'm not crazy\n",
      "\n",
      "POST: I'm not a doctor, but I have lupus. It sounds like lupus to me. Did you get ANA and ENA tests? I had to beg for them and then the doctors were all miffed because I proved I was sick. Good luck.\n",
      "\n",
      "POST: I got those tests and they came back fine, I was so confident that it was lupus for a while but that negative test has really thrown me !\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Armed Citizen Shoots, Kills Active Shooter At Tulsa Shopping Center.\n",
      "\n",
      "POST: So a woman got in an altercation, got mad and grabbed a gun and starting shooting, and was then shot by someone else.\n",
      "\n",
      "POST: The whole situation wouldn't have happened if she didnt have easy access to a gun\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Gay trump supporter talks real big about his experience storming the capitol until he realizes there are consequences to his actions.\n",
      "\n",
      "POST: I get that it's weird that someone from the lgbtq+community supports fascists who want people like him to die, but I don't see his sexual identity having any relevance to this story.\n",
      "\n",
      "POST: It isn't particularly relevant, but instinct magazine strictly covers LGBT stories, so for them it is. Also as a gay man, I get extra jollies from the intense irony of him being a gay trump supporter. Its not necessary for the story but it certainly enhances it.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Ned, the actor behind Micheal, was recently admitted in the hospital for Covid Pneumonia, hoping for his good health and be well soon\n",
      "\n",
      "POST: First we nearly lost Dr. Dre now we might lose Michael. This is getting progressively worse, I hope he pulls through. I'm sure he will tho\n",
      "\n",
      "POST: I almost forgot about Dre\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Why is there so much turmoil towards the pharmaceutical industry among the general public ? And do professionals in this field feel the same way about the field ?\n",
      "\n",
      "POST: It's an industry like any other. The outrage is mostly aimed at outrageous pricing for their products *in America*. That's not the fault of that industry at the core, it's the fault of a political system allowing it. We don't suffer from that where I live, and we get our medicine from the same industry. And you have to keep one thing in mind, development of medications is brutally expensive. That leads to another problem. The industry wants to make profit, and consequently directs their efforts at products that will sell well. Medication for rare conditions will never recoup the development cost and consequently don't get researched. That's another systemic problem.\n",
      "\n",
      "POST: many people have been calling out science subreddit mods like mvea etc for spamming \"shill articles\" etc. And I've begun to question it myself after seeing so many clickbait articles around on r/science. Are those claims true ?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What was your 'I don't get paid enough for this' moment at work?\n",
      "\n",
      "POST: My boss insisted that everybody be at their desks at 8:30 sharp. She made me take roll on an attendance sheet and hand it into her everyday. She also made me do it at lunch time (when everybody left and came back) and when they left at night. Took roll for a bunch of adults three times a day. I don't work there anymore.\n",
      "\n",
      "POST: Oh man, I'm actually relieved, because I had to do this same shit to my subordinates, and honestly I made up numbers 99% of the time because they worked their full hours and could prove it, and their performance was the best in the office because they weren't being crushed by an asshole dictator. I left after I was told to follow my subordinates to the bathroom to time their breaks in there, and one of my team was a pregnant woman. When I objected, I was told by the highest management that I was immature, not a team player, and I had to do exactly everything I was told, no questions asked. No exaggeration, those are direct quotes. I made sure my folks were covered and handed in my resignation. After I left, my friends there told me that a bunch of other people walked too. It was a great place to work for my first two years, but the manager had never held that position, was stubborn, and hated millennials, and so went out of her way to be horrible to her own staff. No ragerts, yo.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Teaching my 6 year old sister how to play dbd is amazing and incredibly frustrating as well\n",
      "\n",
      "POST: 6 is a bit too young, especially a game about killing people\n",
      "\n",
      "POST: Hey tell her that she sees me play this daily and she wanted me to teach her how\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: This duck got trapped under the ice (xpost from /r/nonononoyes)\n",
      "\n",
      "POST: I don't think this poor duck was being helped\n",
      "\n",
      "POST: No. They were being hunted. Please take this down u/the_ebb_and_flow\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Gregory Maxwell is still convinced that a 1mb block size limit was good for Bitcoin adoption.\n",
      "\n",
      "POST: They are backward like that. Best we move on with the solution. Bitcoin Cash proves they were wrong about this and many other things.\n",
      "\n",
      "POST: well, until it has more tx and more hashpower, not to mention higher price, bch does not prove a damn thing...\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Do you use tire shine?\n",
      "\n",
      "POST: I think it's more of a practical thing, rather than a preference. A brand new tire is dark black and matte. Yes, that does look great. However after getting some sun a tire turns grey'ish and kind of chalky. It's just cheap and readily available to grab some tire shine and quickly make them dark black and shiny! There may be product out there for dark black and matte, but I'm assuming the shine is just cheaper and more readily available.\n",
      "\n",
      "POST: Of course there are other products out there. 303, Perl, and others are dressings which are not high shine.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Which scenario is the most common when it comes to the reasons women divorce?\n",
      "\n",
      "POST: Please actually look at the divorce/marriages statistics first:[Here's more statistics on Divorce!](<URL>) * Lack of commitment 73% * Argue too much 56% * Infidelity 55% * Married too young 46% * Unrealistic expectations 45% * Lack of equality in the relationship 44% * Lack of preparation for marriage 41% * [Domestic Violence](<URL>) or Abuse 25% (Respondents often cited more that one reason, therefore the percentages add up to much more than 100 percent)\n",
      "\n",
      "POST: Wow! That website has some startling statistics on how female sexual history impacts marriage: > - Women who lost their virginity as a teenager are more than twice as likely to get divorced in the first 5 years of marriage than women who waited until age 18 or older. > - Women with 6 or more premarital sexual partners are almost 3 times less likely to be in a stable marriage. Female sexual history obviously plays a big role in the success of marriage.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: I need help with a debate\n",
      "\n",
      "POST: What is he saying/rephrasing?\n",
      "\n",
      "POST: I'll give you an example, I was telling him about how hell is not justifiable in any way. He repeatedly said that sinning against god is the worst sin so it is and he just kept saying it in different ways.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: CMV: The NRA is a terrorist organization, and it would be legal under the Insurrection act for the US to take military action against it\n",
      "\n",
      "POST: No. The NRA does not use terror to stop common sense laws that would stop those deaths. Background checks are common sense, assault weapon bans are not. With the amount of weapons in the USA and the ease of smuggling in the country assault weapon bans wouldn't do anything because you could still get then illegally. The majority of gun deaths don't happen because someone who legally owns a gun does something illegal. The majority of deaths happen because someone who illegally owns a gun does something illegal. Restrictions on acquisitions are not going to stop that. Enforcement of possession laws will stop that and no politician is campaigning to do that. Even though the NRA would presumably be fine with it.\n",
      "\n",
      "POST: The NRA commits terror by encouraging circumstances and laws which lead to 30,000 deaths a year The majority of gun deaths are carried out by legal gun owners with no criminal records. 20,000 of the 30,000 gun deaths are caused by legal owners who have never been arrested.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Jason? Welcome to Tarrey Town!\n",
      "\n",
      "POST: How would you ever forget someone who is allowed in Tarrey Town\n",
      "\n",
      "POST: Exactly! JaSON moves to Tarrey Town and sells um... cargo shorts.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: I wonder why...\n",
      "\n",
      "POST: If a child rapist is sent to prison do you think I'm gonna care if someone does the same to them?\n",
      "\n",
      "POST: What about the criminals who aren't child rapists? What about the men who go to prison because they couldn't pay child support? What about men imprisoned due to false accusations? What about men in prison due to drugs or theft or anything else non-sexual? Do they deserve it too?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: How is it possible for someone who says he is a liberal to also believe in gun rights and having fiscally responsible government?\n",
      "\n",
      "POST: Because contrary to what the major political parties and media want you to believe, not everyone fits into boxes.\n",
      "\n",
      "POST: Everyone fits into boxes, just sometimes they're boxes with only one person in. Politics isn't broad-strokes. It's extremely individualized. This is why I don't get along with many leftists despite being very far left myself.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: 2020 Super Twosday Discussion Live Thread - Part V\n",
      "\n",
      "POST: Young people who do not vote should be shamed. What can we do to get more young people involved? The barriers today are much less than any other time in history, eg women and people of color segregation and disenfranchisement\n",
      "\n",
      "POST: Get older people to stop shaming young people and voting for their own old ass candidates.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Slayer's Dave Lombardo Shares Opinion on Metallica's Lars Ulrich\n",
      "\n",
      "POST: I'm not a musician so bear with me here. Why the constant debate about Lars' skills? If a successful band in any genre was based only on the very best technical players there would only be a handful of bands out there to listen to right?\n",
      "\n",
      "POST: It is fair to say that Lars, in the grand scheme of heavy metal drummers, ranks lower when it comes to technical skills, especially compared to the likes of Lombardo or Menza, and his drumming has only gotten lazier and sloppier with time. However, the drumming on the first four albums, especially AFJA, was pretty solid. The fact is, Lars is responsible for some of the most memorable drum parts in metal (like the machine gun double bass part in One) and he is absolutely indispensable to the songwriting process with James. Lars, Kirk and even Cliff have all been criticized for their technical skills, but their creativity, along with James (who is an excellent songwriter and rhythm guitarist), was what made Metallica the greatest metal band of all time, not their chops.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: China like the interview,but who is Dr.Lobster?\n",
      "\n",
      "POST: It's a reference to Peterson. He claimed that hierarchies are good because lobsters have hierarchies as well so it's natural.\n",
      "\n",
      "POST: He claimed hierarchies are natural, since we can trace hierarchies to lobsters.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: [Max Payne 3] Think max might be popping too many painkillers at this point tbh\n",
      "\n",
      "POST: Max payne had plenty of glitchy craziness, loved it though\n",
      "\n",
      "POST: Max Payne 3 is such a hidden gem. The story is awful compared to the previous two games, but the gameplay is fucking fantastic. The multiplayer was really fun too. Also, this game has the best flip-flop sandal physics I've ever seen in a videogame thus far.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Scandinavians of reddit: a lot of the internet thinks you live in a perfect fantasy utopia. What are some issues affecting your countries that the world should know about?\n",
      "\n",
      "POST: I've lived in Denmark for two years. People are pretty difficult to get close to there (quite introverted) so you can easily end up being lonely. The political correctness can be annoying too if you happen to have different political views than most Scandinavians.\n",
      "\n",
      "POST: Spot on with the political correctness. I have a couple of quite liberal viewpoints (weed and prostitution should be legal etc), and if my family found out they'd probably all think I was the devil in disguise. Having an opinion that goes against the grain here is not appreciated in the least. You say we have issues with our immigration policies? You're a racist. You say weed should be legal? You're trying to kill our children with drugs. You don't want to go to university just so you can use your diploma to become a cashier? You're a lazy bum who will never succeed at anything\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Thinking about getting a bearded dragon so I'm gonna start my research right here in this subreddit.\n",
      "\n",
      "POST: Let me stop you right there...getting information from this subreddit is a sure fire way to ensure you have absolutely no clue what to do. What will happen is you're going to start an argument between 100 different internet \"experts\" all convinced they know what's best for you. Use veterinary sources to guide your thinking.\n",
      "\n",
      "POST: Alright good to know, thanks. But maybe you can help me out with one thing, there are so many pictures with people using paper towels instead of substrate. Is that at least a thing everybody is okay with?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: 'Blow Up the Phones': Demands That #BoltonMustTestify Surge After New Revelations About Ukrainian Aid Freeze. \"We are citizens of the United States of America, and we must indeed unite together to stop this GOP cover-up.\"\n",
      "\n",
      "POST: Cover up of what?\n",
      "\n",
      "POST: Trump using taxpayer dollars appropriated by Congress to bribe Ukraine into helping his reelection campaign\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Yes, this is a poll about raiding and instances.\n",
      "\n",
      "POST: There is a compromise: Popped bosses. You do a bunch of stuff/farming/crafting to assemble an item that will spawn the boss in the open world. It will automatically be claimed by the group that spawns it. Is it still possible to grief? Yes, but it's more limited. On another note, then I would like to see stuff like BCNMs from FFXI.\n",
      "\n",
      "POST: I like this a lot, though I still would like to see a lockout timer for the party that spawns it. Only because, while the requirement may seem intense and unrepeatable when it's first discovered, inevitably raiding guilds will amass the supplies to farm the item, and thus the boss, and will need to be slowed down. But otherwise, I think this is a great way to let a group try the raid when they're ready on their own time, without being punished by raid guilds. :) Now, I never played FFXI; what are BCNMs?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What is going on with my toenails?! It is painful, it is ugly and I am so ready to be rid of it.\n",
      "\n",
      "POST: I'd say it's damage of scarring of the nail bed by trauma (long time standing and poor fitting shoes). You can see from the ridges of the nail that it's become thickened in response to the trauma. Nothing much you can really do my friend apart from having the nail removed (which I did as mine were much worse that yours).\n",
      "\n",
      "POST: Thank you for answering - how was it to get the nails removed? Did it hurt at all - or is it like when you get teeth removed and it just feels very, very strange? And I completely agree that this wont go away on its own. Should I try the GP/doctor again or find a specialist foot doctor?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Was happy to receive my first ThinkPad which is a T450. eBay posting was wrong and listed it as a 1920x1080 display and I knew right away it wasn't.\n",
      "\n",
      "POST: So if it was advertised with the 1080p screen, but doesn't have that, you could get a refund and return it - \"not as described\" - or, contact the vendor and negotiate a rebate.\n",
      "\n",
      "POST: Im hoping I can negotiate a rebate because Id prefer to keep the machine and upgrade the screen myself\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: This may get me cancelled\n",
      "\n",
      "POST: tl;dr: rushed and rejected from one sorority, should I rush another? Answer: yes\n",
      "\n",
      "POST: I'll correct you lol because I don't want it to look spiteful and NPHC's demeanor towards Greek life is a little different... TL;DR: rushed and rejected from one sorority, didn't like how the chapter handles themselves as a whole, should I rush another sorority that may align with my views better even if they are \"rivals\".\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"no\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Teachers\n",
      "\n",
      "POST: 1 month late, but taught every grade from 4th to 12th at any given point in 4 years as a teacher\n",
      "\n",
      "POST: You taught 4 different grades per year??\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What makes a people think they're smart, when they really aren't?\n",
      "\n",
      "POST: confirmation bias.\n",
      "\n",
      "POST: Yeah, what he said.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Buy and sell in SD?\n",
      "\n",
      "POST: 1. Craigslist 2. Your stuff isn't worth nearly as much as you think 3. You may end up having to pay somebody to haul some of your stuff away 4. Again, craiglist 'gigs' is a good place to find somebody to pay to haul your 'valuables' away\n",
      "\n",
      "POST: Thank you! Needed a bit of grounding during the move out anxiety haha.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: In mid-December, a model from the CA government predicted 75K COVID hospitalizations by mid-January, steep growth from the 16K then hospitalized. Yesterday, CA had less than 21K COVID hospitalizations.\n",
      "\n",
      "POST: In all honesty have we seen one single Covid related model turn out to be correct or even close in the past 10 months?\n",
      "\n",
      "POST: Every one I remember seeing has proven itself to be between 50% and 90% overstated. Our death counts ended up being 10% of what the models were forecasting. One of the cities here went from three overflow hospitals to finding locations for one back in April, then only building a permanent one which has never been staffed. They claim they don't have the personnel to staff them....despite the state's NG being given authorization from our governor to send its stock of nurses and doctors to do it. It makes me wonder of it was just the usual bureaucratic waste or if they've got a future use in mind for the facility...\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: High-calorie sandwiches?\n",
      "\n",
      "POST: Peanut... butter...??? Also you could drizzle olive oil on bread and toast it to increase calorie intake. Use brioche bread (super high calorie and unhealthy)\n",
      "\n",
      "POST: I dont like peanut butter unfortunately, I like your olive oil idea though. Thanks!\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Has anyone spent a lot of time using spaced repetition notecards (like with Anki, etc.), particularly with reviewing blunders on your games?\n",
      "\n",
      "POST: FWIW I remember this podcast episode where the guest talked about using notecards <URL>\n",
      "\n",
      "POST: Came here to comment this. I think she said she got the trick from John Bartholomew.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Political double standard\n",
      "\n",
      "POST: The mustard thing really drives me crazy because he was at a deli. He wasn't at some persons house calling them trash when they didn't have his preferred condiment, they're supposed to have that stuff. It's like getting mad at someone when they ask for marinara at a pizza joint.\n",
      "\n",
      "POST: What gets me the most about the whole thing is Hannity trying to make Obama sound all elite and fancy and out of touch for wanting dijon mustard. Dijon mustard isn't even fancy or special or anything. It's like $2 a jar.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What makes you play this over post scriptum?\n",
      "\n",
      "POST: I feel like HLL is more of a hardcore BF where as PS looks more like Arma Lite. I want to enjoy a shooter with team work and strategy on a large scale. I like the relatively fast paced gameplay, less down time, more engagements, smaller maps and leathal weapons make for epic flanks, as a result i feel like as a single player i can have a decent impact on a game - i just enjoy the pacing and the way combat plays out (im nervous that the infantry vehicles will fuck this up). I'll admit that PS's wider range of factions does look very attractive but at the end of the day whats the point in having all these unique and interesting guns and what not when for most of the game you arent going to be using them because your going to be on the move and then when you do its spamming suppressing fire at a hedge. Edit: to be clear i might be 100% wrong about PS i havent played it but thats just the vibe i got from the gameplay ive seen.\n",
      "\n",
      "POST: You havent played but are talking about it like this? Oof\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: What if the trait is humanity?\n",
      "\n",
      "POST: Circular/tautological reasoning. You're assuming your conclusion to be true in yoir premises, and the argument doesn't move* in any direction. > P1: Humans have moral value. (Conclusion assumed in premises.) > P2: Humans are human. (Tautology.) > C: Humans have moral value.\n",
      "\n",
      "POST: It's not circular at all because NTT doesn't revolve around proving human moral value.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Got this 41 year old Soviet electronic calculator back up and running, just needed new caps!\n",
      "\n",
      "POST: Awesome! Now make it say boobs.\n",
      "\n",
      "POST: / Buffer overflow (The Russian word (*bufyer* or *boofer*) can mean both \"buffer\" and \"boob\"; the connection is via railroad buffers, the twin shock absorbers used to dampen the impact of a train car hitting a stop.)\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: NFL Player wants NFL to consider permitting marijuana use for pain management\n",
      "\n",
      "POST: question, both medical marijuana and adderall are both banned NFL substances. Adderall is allowed with a prescription, so why wouldn't medical marijuana be allowed with a prescription if a player is in a state where medical marijuana is legal? edit. /u/btbrian makes a great point. \"For one thing, it would inherently give players in states where it is legal an edge if it does have performance related (pain management) effects like they claim\"\n",
      "\n",
      "POST: NFL is a national organization and most likely follow federal laws. Lots of companies in green states don't allow marijuana use because of that or because they can still just make it their policy\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: In search of a dog groomer experienced with anxious dogs\n",
      "\n",
      "POST: There is a place off republic road called Fetch. You can bathe your dog there and they provide brushes, towels, shampoo. If you go on Wednesday it is half price for dog wash Wednesday.\n",
      "\n",
      "POST: Oh man, I completely forgot that they make those wash your own pet here things. Thanks for the reminder, going to go this week.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Master of Magic : Master of No Magic\n",
      "\n",
      "POST: Loooool. Their immunity is so op. I thought this was going to be a warlord war trolls run or something from the title\n",
      "\n",
      "POST: This playthrough came about because someone asked if I had ever thought about playing a game with no books. You can get no books, but it screws up some of the retort picks ( you can only have 6). So you end up taking channeler and having to lose out on a better pick like artificer/conjurer/famous.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Can we consider humans as an invasive specie?\n",
      "\n",
      "POST: Not by definition. [<URL>](<URL>)\n",
      "\n",
      "POST: Interesting article and thanks for sharing, but let me to be skeptic about: *\" 3) An invasive species is introduced to a new habitat: Humans move themselves; there is no outside entity facilitating their spread.* *4) An invasive species had adverse effects on its new habitat and/or on human health: Humans meet this part of the definition in too many ways to count. \"* If we observe the increase level of [world population](<URL>), and we observe in [Google Maps](<URL>) how cities and towns are growing their [urban areas](<URL>), and all the impacts in climate change especially about the [consumption of natural resources](<URL>) , I think it is a possibility to consider humans are invasive species.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: The sex offender registry should only be for people for individuals who pose a risk to the safety of others. Not some 16 year old who sent a dick pic!\n",
      "\n",
      "POST: Imagine being a horny naive 16 year old. You were talking to a girl, you guys exchange nudes. You're 21. It's been revealed to other adults that you sent a picture of your dick (nice cock btw). You're on the sex offender registry. You will get almost all job offers turned down. Your life is fucked because someone decided your life should be shit for being a horny teenager.\n",
      "\n",
      "POST: 21 year old aren't teenagers\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: [For Hire] Computer Science Grad.\n",
      "\n",
      "POST: Have you talked to a local recruiter? They can often place you in a position that fits your skills.\n",
      "\n",
      "POST: No not yet, have any recommendations?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: I looked it up the tweet does not lie the traitor did indeed take a fat one\n",
      "\n",
      "POST: let's not use homophobia as an insult, okay?\n",
      "\n",
      "POST: Dude its a porn parody about a homophobe\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: No mans sky performance \"quest\"ions\n",
      "\n",
      "POST: try setting VRCompositor and VRServer priority to real time from task manager. this seems to be a general solution for microstuttering in certain pcs. also make sure the Nvidia in-game overlay is disabled (geforce experience setting)\n",
      "\n",
      "POST: do i have to have vr on to find these settings?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Dolly's Braces\n",
      "\n",
      "POST: [Nerdy girl with pigtails and braces is a common stereotype](<URL>). Dolly looks very similar to that stereotype, thus people get the details mixed up. That said, this is one of the best MEs around as it would fit really well together with Jaws, so it's weird that they didn't use braces in the movie.\n",
      "\n",
      "POST: That's a pretty big \"thus\" you've thrown into the mix there. If this was just people getting details mixed up, the Mandela Effect would not sustain the interest it has.\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Any suggestions on good conspiracy books?\n",
      "\n",
      "POST: Not really conspiracy-related, but I'd recommend *\"The Demon-Haunted World: Science as a Candle in the Dark\" by Carl Sagan*, as it explains methods to help distinguish between ideas that are considered valid science, and ideas that can be considered pseudoscience.\n",
      "\n",
      "POST: Sagan doesn't really go into history as much as he talks about the history of pseudoscience. It is better to learn something like the [Trivium method](<URL>) before doing your own research. The Trivium method gives a great toolset for anybody to learn and research for themselves. It is also very helpful to learn about [fallacies](<URL>), as well.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What's something that you like, but hate the fan base?\n",
      "\n",
      "POST: Anime. Every time I find one that I like. I mention it to other people and then they feel the need to shit on whatever I'm watching and say I should watch something else because it's better.\n",
      "\n",
      "POST: Honestly, as an anime fan, i haven't really experienced this. It may be my group of friends or something being less combative about anime that they like, but i only come across the occasional person like that when i mention black clover really.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Plant food damage while a Power Mint is activated\n",
      "\n",
      "POST: It depends on the plant. Some do get boosted, some don't.\n",
      "\n",
      "POST: I dont think it depends on the plant. Are you sure that you understood my question? Anyway, if you are sure, does Parsnip get boosted?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Biden's plan increases UI by $1600/month, increase food stamps by 15%, gives every family $3000/yr per child (extra 600 per child if under 6), adds 14 weeks of paid leave, extends the rent moratorium, cuts child poverty in 1/2, and raise the minimum wage to $15. Why are leftists STILL mad?\n",
      "\n",
      "POST: Who is mad about this? What did I miss?\n",
      "\n",
      "POST: a lot of leftists are mad that its 1400 checks not 2000, because it was meant to supplement the 600 passed in december\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Debate on the authenticity of the Qur'an\n",
      "\n",
      "POST: Yes, there has been a response. Here's a point by point refutation of each claim made, along with full citations listing and quotes: <URL> I'm the author of the paper, so I'd be willing to answer any questions you have.\n",
      "\n",
      "POST: Did you send this to either of the speakers? Just curious as if you took the time to actually debate each of his points, it'll be interesting to hear both of the speakers thoughts on it.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: The Decision Not to Call in the FBI is Looking Worse and Worse\n",
      "\n",
      "POST: It just doesn't make sense. If Kavanaugh is innocent he should be yelling from the hills demanding an investigation by the FBI.\n",
      "\n",
      "POST: Let's remember also that *it is a crime to lie to federal law enforcement.* (See Michael Flynn, George Papadapapapolis, Carter Page, etc.) If Dr. Ford *is* lying, then Republicans should be *eager* to get her in front of an FBI interrogator. Can you imagine what kind of huge political win that would be for Republicans? >\"Breaking News: 'Me too' Democrat lies to FBI and is facing jail time just weeks before the midterm elections, vindicating Justice Kavanaugh and President Trump in the process. And after that, is political correctness killing your dog? We scream, you decide.\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: Did not think it was possible\n",
      "\n",
      "POST: This isn't impossible odds at all. It makes sense that the bar would snap when he was in a position to land, it would be bizarre if it didn't. That's the point at which the most weight is pulling on it, due to gravity.\n",
      "\n",
      "POST: Would've thought it was designed to resist downwards force more than lateral or upwards though as that's how most people would use it.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: I'm writing an essay about putting forth a case to use a Jungian lens when examining and critiquing literature and need help finding a scholarly article or study about why men are interested in things whereas women are interested in people. Must be a biological or psychological article.\n",
      "\n",
      "POST: I would be more indifferent to this assertion but for the established reality that *some* men use it as a tool to minimize the importance of women's perspective on life, the universe and everything.\n",
      "\n",
      "POST: Could you clarify this? Not sure if Im interpreting what you are saying correctly Im using it as a point that the Postmodernist lens when critiquing literature doesnt include facts in their analysis.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: 74% of voters also say they support the federal government breaking up large technology companies to reduce their power and increase competition and innovation\n",
      "\n",
      "POST: So what would be the down side of this? I'm just curious if someone could tell me that would be great.\n",
      "\n",
      "POST: The government has no right to spilt up your business\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: The Qanon crowd is realizing there's no storm coming\n",
      "\n",
      "POST: Four years of faith in internet strangers over their own friends and families is ending exactly as expected.\n",
      "\n",
      "POST: I still don't think the whole QAnon thing was real. I think it was made up by trolls to see how much stupid shit they could get people to believe.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: 'One job should be enough': Marriott hotel workers' strike hits eight US cities\n",
      "\n",
      "POST: I shouldn't be a race to the bottom, thankless jobs like EMTs should get paid far more than they do now, nobody is saying that minimum wage workers should get paid more than them. To those who argue *well x job pays y amount* do you think that maybe they should get a significant wage hike to so they don't live in poverty either?\n",
      "\n",
      "POST: > To those who argue well x job pays y amount do you think that maybe they should get a significant wage hike to so they dont live in poverty either? For real, I don't understand why this is so hard for people. But every time I bring this point up, GOP_Fanboy just reverts to \"lol who are you to decide who gets paid what communist etc\"\"\n",
      "Label(s): \"['fallacy']\"\n",
      "Generated text: \"AA, no fallacy BB\"\n",
      "-> incorrect\n",
      "\n",
      "Text: \"TITLE: That rock sounds kinda nice ngl\n",
      "\n",
      "POST: Apart from the moral issue, \"just join the military\" does nothing for young people with disabilities or conditions that disqualify them. And before some asshole says something like, \"Harhar just lose weight,\" there are waaaay more disqualifying issues than that and many are totally out of a person's control.\n",
      "\n",
      "POST: Never thought about this. What about clerical jobs in the army? Every organization needs desk jockeys. Would those just be \"normal\" jobs, as compared to enlisting in the army?\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: New Zealand announces official Travel Warning to New Zealanders in the United States due to the upcoming election and civil unrest\n",
      "\n",
      "POST: This sounds like the sort of thing you hear about Middle East countries not the formerly most powerful nation in the world.\n",
      "\n",
      "POST: Dictatorships have occurred all throughout history and all corners of the globe. It takes a severe amount of head in the sand to think it can't happen to you.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: Fuck politics\n",
      "\n",
      "POST: He *does* talk about politics. What JP *doesn't* do is circle jerk with the right. I think that's what you meant to say - \"can we stop with the right-wing circle jerk?\"\n",
      "\n",
      "POST: Yeah but i just think if we go into politics, we should go with as little bias as possible and that's not what's happening here.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA\"\n",
      "-> correct\n",
      "\n",
      "Text: \"TITLE: What are the most cowardly things a person can do? POST: Refusing to acknowledge that you made a mistake and making excuses instead of being better. We're human. We're flawed - all of us.\"\n",
      "Label(s): \"['no fallacy']\"\n",
      "Generated text: \"AA, BB.\"\n",
      "-> correct\n",
      "\n",
      "Got 63 out of 200 correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompting model:   0%|          | 0/200 [00:00<?, ?it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   0%|          | 1/200 [00:00<02:01,  1.64it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   1%|          | 2/200 [00:00<01:27,  2.27it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   2%|         | 3/200 [00:01<01:26,  2.28it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   2%|         | 4/200 [00:01<01:34,  2.07it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   2%|         | 5/200 [00:02<01:25,  2.29it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   3%|         | 6/200 [00:02<01:23,  2.32it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   4%|         | 7/200 [00:03<01:18,  2.44it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   4%|         | 8/200 [00:03<01:15,  2.54it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   4%|         | 9/200 [00:03<01:18,  2.42it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   5%|         | 10/200 [00:04<01:12,  2.61it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   6%|         | 11/200 [00:04<01:07,  2.79it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   6%|         | 12/200 [00:04<01:08,  2.73it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   6%|         | 13/200 [00:05<01:05,  2.85it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   7%|         | 14/200 [00:05<01:03,  2.94it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   8%|         | 15/200 [00:05<01:06,  2.79it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   8%|         | 16/200 [00:06<01:14,  2.46it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   8%|         | 17/200 [00:06<01:12,  2.52it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:   9%|         | 18/200 [00:07<01:09,  2.62it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  10%|         | 19/200 [00:07<01:19,  2.28it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  10%|         | 20/200 [00:08<01:19,  2.28it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  10%|         | 21/200 [00:08<01:09,  2.58it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  11%|         | 22/200 [00:08<01:09,  2.54it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  12%|        | 23/200 [00:09<01:19,  2.24it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  12%|        | 24/200 [00:09<01:11,  2.47it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  12%|        | 25/200 [00:10<01:08,  2.54it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  13%|        | 26/200 [00:10<01:07,  2.59it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  14%|        | 27/200 [00:10<01:12,  2.38it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  14%|        | 28/200 [00:11<01:11,  2.42it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  14%|        | 29/200 [00:11<01:04,  2.64it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  15%|        | 30/200 [00:12<01:07,  2.50it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  16%|        | 31/200 [00:12<01:08,  2.47it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  16%|        | 32/200 [00:12<01:05,  2.58it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  16%|        | 33/200 [00:13<01:20,  2.06it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  17%|        | 34/200 [00:13<01:15,  2.19it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  18%|        | 35/200 [00:14<01:10,  2.32it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  18%|        | 36/200 [00:14<01:07,  2.41it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  18%|        | 37/200 [00:15<01:17,  2.10it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  19%|        | 38/200 [00:15<01:16,  2.11it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  20%|        | 39/200 [00:16<01:06,  2.41it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  20%|        | 40/200 [00:16<01:00,  2.64it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  20%|        | 41/200 [00:16<01:00,  2.63it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  21%|        | 42/200 [00:17<00:57,  2.74it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  22%|       | 43/200 [00:17<01:00,  2.59it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  22%|       | 44/200 [00:18<01:21,  1.91it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  22%|       | 45/200 [00:18<01:19,  1.96it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  23%|       | 46/200 [00:19<01:13,  2.08it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  24%|       | 47/200 [00:19<01:06,  2.31it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  24%|       | 48/200 [00:19<01:02,  2.45it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  24%|       | 49/200 [00:20<01:01,  2.47it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  25%|       | 50/200 [00:21<01:16,  1.96it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  26%|       | 51/200 [00:21<01:07,  2.20it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  26%|       | 52/200 [00:21<01:10,  2.10it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  26%|       | 53/200 [00:22<01:01,  2.39it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  27%|       | 54/200 [00:22<00:59,  2.43it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  28%|       | 55/200 [00:23<01:01,  2.38it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  28%|       | 56/200 [00:23<00:57,  2.52it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  28%|       | 57/200 [00:23<00:55,  2.57it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  29%|       | 58/200 [00:24<00:57,  2.47it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  30%|       | 59/200 [00:24<00:55,  2.54it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  30%|       | 60/200 [00:25<00:58,  2.40it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  30%|       | 61/200 [00:25<01:05,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  31%|       | 62/200 [00:25<00:59,  2.30it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  32%|      | 63/200 [00:26<01:01,  2.24it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  32%|      | 64/200 [00:26<00:55,  2.46it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  32%|      | 65/200 [00:27<01:02,  2.15it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  33%|      | 66/200 [00:28<01:16,  1.76it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  34%|      | 67/200 [00:28<01:07,  1.96it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  34%|      | 68/200 [00:28<01:02,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  34%|      | 69/200 [00:29<00:54,  2.40it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  35%|      | 70/200 [00:29<01:06,  1.96it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  36%|      | 71/200 [00:30<01:00,  2.15it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  36%|      | 72/200 [00:30<00:55,  2.29it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  36%|      | 73/200 [00:31<00:51,  2.44it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  37%|      | 74/200 [00:31<00:54,  2.30it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  38%|      | 75/200 [00:32<00:59,  2.09it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  38%|      | 76/200 [00:32<01:01,  2.01it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  38%|      | 77/200 [00:33<01:02,  1.97it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  39%|      | 78/200 [00:33<01:02,  1.94it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  40%|      | 79/200 [00:34<00:59,  2.04it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  40%|      | 80/200 [00:34<00:50,  2.35it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  40%|      | 81/200 [00:34<00:56,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  41%|      | 82/200 [00:35<00:56,  2.08it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  42%|     | 83/200 [00:35<00:50,  2.30it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  42%|     | 84/200 [00:36<00:48,  2.39it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  42%|     | 85/200 [00:36<00:59,  1.93it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  43%|     | 86/200 [00:37<00:54,  2.10it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  44%|     | 87/200 [00:37<00:54,  2.08it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  44%|     | 88/200 [00:38<00:51,  2.19it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  44%|     | 89/200 [00:38<00:44,  2.47it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  45%|     | 90/200 [00:38<00:45,  2.42it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  46%|     | 91/200 [00:39<00:41,  2.60it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  46%|     | 92/200 [00:39<00:40,  2.67it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  46%|     | 93/200 [00:39<00:37,  2.84it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  47%|     | 94/200 [00:40<00:35,  2.98it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  48%|     | 95/200 [00:40<00:35,  2.97it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  48%|     | 96/200 [00:40<00:35,  2.95it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  48%|     | 97/200 [00:41<00:38,  2.70it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  49%|     | 98/200 [00:41<00:41,  2.49it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  50%|     | 99/200 [00:42<00:41,  2.44it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  50%|     | 100/200 [00:42<00:39,  2.51it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  50%|     | 101/200 [00:43<00:43,  2.30it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  51%|     | 102/200 [00:43<00:44,  2.19it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  52%|    | 103/200 [00:43<00:40,  2.38it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  52%|    | 104/200 [00:44<00:51,  1.86it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  52%|    | 105/200 [00:45<00:47,  2.00it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  53%|    | 106/200 [00:45<00:44,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  54%|    | 107/200 [00:45<00:40,  2.27it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  54%|    | 108/200 [00:46<00:41,  2.20it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  55%|    | 109/200 [00:46<00:38,  2.38it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  55%|    | 110/200 [00:47<00:38,  2.35it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  56%|    | 111/200 [00:47<00:35,  2.48it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  56%|    | 112/200 [00:48<00:37,  2.36it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  56%|    | 113/200 [00:48<00:41,  2.09it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  57%|    | 114/200 [00:48<00:36,  2.35it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  57%|    | 115/200 [00:49<00:45,  1.87it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  58%|    | 116/200 [00:50<00:46,  1.82it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  58%|    | 117/200 [00:50<00:40,  2.03it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  59%|    | 118/200 [00:51<00:37,  2.19it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  60%|    | 119/200 [00:51<00:37,  2.14it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  60%|    | 120/200 [00:52<00:41,  1.91it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  60%|    | 121/200 [00:52<00:39,  2.00it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  61%|    | 122/200 [00:53<00:37,  2.08it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  62%|   | 123/200 [00:53<00:33,  2.33it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  62%|   | 124/200 [00:53<00:32,  2.37it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  62%|   | 125/200 [00:54<00:33,  2.26it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  63%|   | 126/200 [00:54<00:31,  2.33it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  64%|   | 127/200 [00:55<00:29,  2.48it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  64%|   | 128/200 [00:55<00:29,  2.43it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  64%|   | 129/200 [00:55<00:30,  2.37it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  65%|   | 130/200 [00:56<00:27,  2.53it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  66%|   | 131/200 [00:56<00:25,  2.73it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  66%|   | 132/200 [00:57<00:30,  2.26it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  66%|   | 133/200 [00:57<00:29,  2.26it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  67%|   | 134/200 [00:58<00:28,  2.28it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  68%|   | 135/200 [00:58<00:29,  2.17it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  68%|   | 136/200 [00:58<00:28,  2.26it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  68%|   | 137/200 [00:59<00:27,  2.32it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  69%|   | 138/200 [00:59<00:29,  2.07it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  70%|   | 139/200 [01:00<00:27,  2.19it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  70%|   | 140/200 [01:00<00:26,  2.22it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  70%|   | 141/200 [01:01<00:26,  2.21it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  71%|   | 142/200 [01:01<00:26,  2.21it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  72%|  | 143/200 [01:02<00:25,  2.20it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  72%|  | 144/200 [01:02<00:30,  1.84it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  72%|  | 145/200 [01:03<00:34,  1.60it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  73%|  | 146/200 [01:04<00:29,  1.85it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  74%|  | 147/200 [01:04<00:26,  1.97it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  74%|  | 148/200 [01:04<00:24,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  74%|  | 149/200 [01:05<00:23,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  75%|  | 150/200 [01:06<00:26,  1.89it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  76%|  | 151/200 [01:06<00:25,  1.94it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  76%|  | 152/200 [01:07<00:27,  1.77it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  76%|  | 153/200 [01:07<00:24,  1.88it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  77%|  | 154/200 [01:08<00:23,  1.95it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  78%|  | 155/200 [01:08<00:21,  2.09it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  78%|  | 156/200 [01:09<00:21,  2.05it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  78%|  | 157/200 [01:09<00:23,  1.84it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  79%|  | 158/200 [01:10<00:20,  2.09it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  80%|  | 159/200 [01:10<00:18,  2.17it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  80%|  | 160/200 [01:11<00:22,  1.78it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  80%|  | 161/200 [01:11<00:22,  1.71it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  81%|  | 162/200 [01:12<00:20,  1.83it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  82%| | 163/200 [01:13<00:21,  1.70it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  82%| | 164/200 [01:13<00:22,  1.62it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  82%| | 165/200 [01:14<00:20,  1.69it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  83%| | 166/200 [01:14<00:18,  1.82it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  84%| | 167/200 [01:15<00:15,  2.08it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  84%| | 168/200 [01:15<00:13,  2.29it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  84%| | 169/200 [01:15<00:13,  2.29it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  85%| | 170/200 [01:16<00:14,  2.07it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  86%| | 171/200 [01:16<00:13,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  86%| | 172/200 [01:17<00:12,  2.25it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  86%| | 173/200 [01:17<00:11,  2.29it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  87%| | 174/200 [01:18<00:13,  1.92it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  88%| | 175/200 [01:18<00:12,  2.02it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  88%| | 176/200 [01:19<00:11,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  88%| | 177/200 [01:19<00:10,  2.11it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  89%| | 178/200 [01:20<00:10,  2.11it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  90%| | 179/200 [01:20<00:09,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  90%| | 180/200 [01:21<00:10,  1.88it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  90%| | 181/200 [01:21<00:10,  1.87it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  91%| | 182/200 [01:22<00:08,  2.01it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  92%|| 183/200 [01:22<00:07,  2.23it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  92%|| 184/200 [01:23<00:07,  2.18it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  92%|| 185/200 [01:23<00:06,  2.20it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  93%|| 186/200 [01:24<00:06,  2.12it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  94%|| 187/200 [01:24<00:06,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  94%|| 188/200 [01:24<00:05,  2.30it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  94%|| 189/200 [01:25<00:04,  2.36it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  95%|| 190/200 [01:25<00:04,  2.15it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  96%|| 191/200 [01:26<00:04,  1.92it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  96%|| 192/200 [01:26<00:03,  2.06it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  96%|| 193/200 [01:27<00:03,  2.06it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  97%|| 194/200 [01:27<00:02,  2.18it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  98%|| 195/200 [01:28<00:02,  2.31it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  98%|| 196/200 [01:28<00:02,  1.97it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  98%|| 197/200 [01:29<00:01,  2.09it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model:  99%|| 198/200 [01:29<00:00,  2.22it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model: 100%|| 199/200 [01:30<00:00,  2.13it/s]Both `max_new_tokens` (=25) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "\n",
      "Prompting model: 100%|| 200/200 [01:30<00:00,  2.25it/s]\n",
      "                                                                  \n"
     ]
    }
   ],
   "source": [
    "! python prompt_model.py --dataset data/test/mafalda_gold_standard_dataset.jsonl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
